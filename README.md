# Amazon Scraper API - Multi-Country Product Scraping

## üéØ Overview

REST API service for scraping Amazon product data across 15 countries. Built with Flask, Selenium, and BeautifulSoup for reliable data extraction.

## üìÅ Project Structure

```
AmazonScraper/
‚îú‚îÄ‚îÄ api_server.py           # Flask API server
‚îú‚îÄ‚îÄ api_config.py           # Country configurations
‚îú‚îÄ‚îÄ .env                    # Environment configuration
‚îú‚îÄ‚îÄ .env.example            # Example environment file
‚îú‚îÄ‚îÄ requirements.txt        # Python dependencies
‚îú‚îÄ‚îÄ INSTALL.txt             # Complete installation & VPS deployment guide
‚îú‚îÄ‚îÄ README.md               # This file
‚îî‚îÄ‚îÄ scrapers/
    ‚îú‚îÄ‚îÄ base_scraper.py     # Base scraper class
    ‚îú‚îÄ‚îÄ india_scraper.py    # Amazon India
    ‚îú‚îÄ‚îÄ usa_scraper.py      # Amazon USA
    ‚îî‚îÄ‚îÄ uk_scraper.py       # Amazon UK
```

## üöÄ Quick Start

### Prerequisites
- Python 3.7+
- Microsoft Edge browser
- Internet connection

### Installation

1. **Install dependencies:**
```bash
pip install -r requirements.txt
```

2. **Configure environment:**
```bash
copy .env.example .env
```

Edit `.env` and set your API key:
```
API_KEY=your_secret_api_key_here
```

3. **Run the server:**
```bash
python api_server.py
```

Server starts at: http://127.0.0.1:5000

## üì° API Endpoints

### Health Check
```bash
GET /health
```

Response:
```json
{
  "status": "healthy",
  "supported_countries": 15
}
```

### Scrape Product
```bash
POST /api/scrape
Headers: X-API-Key: your_api_key_here
         Content-Type: application/json

Body:
{
  "product_url": "https://www.amazon.in/dp/B0FMDNZ61S"
}
```

Response (12 essential fields):
```json
{
  "success": true,
  "data": {
    "asin": "B0FMDNZ61S",
    "merchant": "Amazon",
    "name": "Product Name",
    "category": "Category",
    "subcategory": "Subcategory",
    "brand": "Brand Name",
    "current_price": 1299.00,
    "original_price": 1999.00,
    "stock_status": "In Stock",
    "image_path": "https://...",
    "rating": 4.2,
    "review_count": 1850
  }
## üåç Supported Countries (15 Amazon Marketplaces)

| Country | Domain | Currency |
|---------|--------|----------|
| üá∫üá∏ United States | amazon.com | USD |
| üá®üá¶ Canada | amazon.ca | CAD |
| üá≤üáΩ Mexico | amazon.com.mx | MXN |
| üáßüá∑ Brazil | amazon.com.br | BRL |
| üá¨üáß United Kingdom | amazon.co.uk | GBP |
| üá©üá™ Germany | amazon.de | EUR |
| üá´üá∑ France | amazon.fr | EUR |
| üáÆüáπ Italy | amazon.it | EUR |
| üá™üá∏ Spain | amazon.es | EUR |
| üá≥üá± Netherlands | amazon.nl | EUR |
| üá¶üá™ UAE | amazon.ae | AED |
| üáÆüá≥ India | amazon.in | INR |
| üáØüáµ Japan | amazon.co.jp | JPY |
| üá¶üá∫ Australia | amazon.com.au | AUD |
| üá∏üá¨ Singapore | amazon.sg | SGD |

## üîß Configuration

### Environment Variables (.env)

```bash
# API Server
API_HOST=0.0.0.0          # 0.0.0.0 for public, 127.0.0.1 for local
API_PORT=5000             # Server port
API_KEY=your_key_here     # Authentication key

# Application
DEBUG_MODE=True           # Enable debug logging
HEADLESS_MODE=False       # Run browser without GUI
BROWSER_TIMEOUT=30        # Browser timeout in seconds

# CORS
ALLOWED_ORIGINS=http://localhost:8000,https://yourdomain.com
```

## üîê Authentication

All API requests require authentication via API key:

**Method 1: Header (Recommended)**
```bash
X-API-Key: your_api_key_here
```

**Method 2: Query Parameter**
```bash
?api_key=your_api_key_here
```

## üèóÔ∏è Architecture

### Base Scraper Class
All country scrapers inherit from `BaseAmazonScraper`:
- Browser initialization with anti-detection
- ASIN extraction from URLs
- Common scraping methods
- Error handling

### Country-Specific Scrapers
Each country has its own scraper module:
- `india_scraper.py` - Amazon India
- `usa_scraper.py` - Amazon USA
- `uk_scraper.py` - Amazon UK
- More countries coming soon...

### Automatic Country Detection
API automatically detects country from product URL:
```python
amazon.in ‚Üí India Scraper
amazon.com ‚Üí USA Scraper
amazon.co.uk ‚Üí UK Scraper
```

## üì¶ Response Fields

The API returns only 12 essential fields (no bloat):

1. **asin** - Amazon Standard Identification Number
2. **merchant** - Seller name (Amazon, Cloudtail, etc.)
3. **name** - Product title
4. **category** - Main category
5. **subcategory** - Subcategory
6. **brand** - Brand name
7. **current_price** - Current price (numeric)
8. **original_price** - Original/MRP price (numeric)
9. **stock_status** - "In Stock" or "Out of Stock"
10. **image_path** - Main product image URL
11. **rating** - Average rating (0-5)
12. **review_count** - Number of reviews

## üîó Laravel Integration

### Service Class
```php
use App\Services\AmazonScraperService;

$scraper = new AmazonScraperService();
$result = $scraper->scrapeProduct('https://www.amazon.in/dp/B0FMDNZ61S');

if ($result['success']) {
    $data = $result['data'];
    // Use data...
}
```

### Configuration (config/services.php)
```php
'amazon_scraper' => [
    'url' => env('AMAZON_SCRAPER_URL', 'http://127.0.0.1:5000'),
    'api_key' => env('AMAZON_SCRAPER_API_KEY'),
    'timeout' => env('AMAZON_SCRAPER_TIMEOUT', 60),
],
```

### Environment (.env)
```bash
AMAZON_SCRAPER_URL=http://127.0.0.1:5000
AMAZON_SCRAPER_API_KEY=1AqqRHyRhnlWzvljsvjD011dROrTeS3jqVxmqZHUFDqnbe1zLZ5bqxE5wVMVXgwF
AMAZON_SCRAPER_TIMEOUT=60
```

## üñ•Ô∏è VPS Deployment (Always Running)

For production deployment on VPS with systemd service (24/7 operation):

**See INSTALL.txt for complete guide including:**
- Ubuntu/Debian setup
- Systemd service configuration
- Nginx reverse proxy
- SSL certificate setup
- Firewall configuration
- Always-running configuration
- Monitoring and logs

Quick command to make it always run:
```bash
sudo systemctl enable amazon-scraper-api
sudo systemctl start amazon-scraper-api
```

## üõ†Ô∏è Development

### Adding New Country Scraper

1. Create new scraper file:
```python
# scrapers/germany_scraper.py
from scrapers.base_scraper import BaseAmazonScraper

class GermanyScraper(BaseAmazonScraper):
    def scrape_product(self, url):
        # Implement Germany-specific scraping
        pass
```

2. Add to `api_config.py`:
```python
AMAZON_COUNTRIES = {
    'DE': {
        'name': 'Germany',
        'domain': 'amazon.de',
        'currency': 'EUR',
        'scraper': 'germany_scraper.GermanyScraper'
    }
}
```

3. Import in `api_server.py`:
```python
from scrapers.germany_scraper import GermanyScraper
```

## üìä Logging

### Development
- Console output with DEBUG_MODE=True
- Real-time scraping progress

### Production
- Output log: `/home/amazonscraper/app/logs/output.log`
- Error log: `/home/amazonscraper/app/logs/error.log`
- Systemd journal: `sudo journalctl -u amazon-scraper-api`

## üêõ Troubleshooting

### WebDriver Issues
```bash
# Auto-download on first run
# Requires internet connection
```

### Port Already in Use
```bash
# Change API_PORT in .env
API_PORT=5001
```

### CORS Errors
```bash
# Add your domain to ALLOWED_ORIGINS
ALLOWED_ORIGINS=https://yourdomain.com,http://localhost:8000
```

### Service Not Starting (VPS)
```bash
# Check status
